{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller: Construcción e implementación de modelos Bagging, Random Forest y XGBoost\n",
    "\n",
    "En este taller podrán poner en práctica sus conocimientos sobre la construcción e implementación de modelos de Bagging, Random Forest y XGBoost. El taller está constituido por 8 puntos, en los cuales deberan seguir las intrucciones de cada numeral para su desarrollo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos predicción precio de automóviles\n",
    "\n",
    "En este taller se usará el conjunto de datos de Car Listings de Kaggle donde cada observación representa el precio de un automóvil teniendo en cuenta distintas variables como año, marca, modelo, entre otras. El objetivo es predecir el precio del automóvil. Para más detalles puede visitar el siguiente enlace: [datos](https://www.kaggle.com/jpayne/852k-used-car-listings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>M_Camry</th>\n",
       "      <th>M_Camry4dr</th>\n",
       "      <th>M_CamryBase</th>\n",
       "      <th>M_CamryL</th>\n",
       "      <th>M_CamryLE</th>\n",
       "      <th>M_CamrySE</th>\n",
       "      <th>M_CamryXLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21995</td>\n",
       "      <td>2014</td>\n",
       "      <td>6480</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13995</td>\n",
       "      <td>2014</td>\n",
       "      <td>39972</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>17941</td>\n",
       "      <td>2016</td>\n",
       "      <td>18989</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>12493</td>\n",
       "      <td>2014</td>\n",
       "      <td>51330</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>7994</td>\n",
       "      <td>2007</td>\n",
       "      <td>116065</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Year  Mileage  M_Camry  M_Camry4dr  M_CamryBase  M_CamryL  \\\n",
       "7    21995  2014     6480    False       False        False      True   \n",
       "11   13995  2014    39972    False       False        False     False   \n",
       "167  17941  2016    18989    False       False        False     False   \n",
       "225  12493  2014    51330    False       False        False      True   \n",
       "270   7994  2007   116065    False        True        False     False   \n",
       "\n",
       "     M_CamryLE  M_CamrySE  M_CamryXLE  \n",
       "7        False      False       False  \n",
       "11        True      False       False  \n",
       "167      False       True       False  \n",
       "225      False      False       False  \n",
       "270      False      False       False  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lectura de la información de archivo .csv\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/dataTrain_carListings.zip')\n",
    "\n",
    "# Preprocesamiento de datos para el taller\n",
    "data = data.loc[data['Model'].str.contains('Camry')].drop(['Make', 'State'], axis=1)\n",
    "data = data.join(pd.get_dummies(data['Model'], prefix='M'))\n",
    "data = data.drop(['Model'], axis=1)\n",
    "\n",
    "# Visualización dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento y Análisis Descriptivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>M_Camry</th>\n",
       "      <th>M_Camry4dr</th>\n",
       "      <th>M_CamryBase</th>\n",
       "      <th>M_CamryL</th>\n",
       "      <th>M_CamryLE</th>\n",
       "      <th>M_CamrySE</th>\n",
       "      <th>M_CamryXLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21995</td>\n",
       "      <td>2014</td>\n",
       "      <td>6480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13995</td>\n",
       "      <td>2014</td>\n",
       "      <td>39972</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>17941</td>\n",
       "      <td>2016</td>\n",
       "      <td>18989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>12493</td>\n",
       "      <td>2014</td>\n",
       "      <td>51330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>7994</td>\n",
       "      <td>2007</td>\n",
       "      <td>116065</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Year  Mileage  M_Camry  M_Camry4dr  M_CamryBase  M_CamryL  \\\n",
       "7    21995  2014     6480        0           0            0         0   \n",
       "11   13995  2014    39972        0           0            0         1   \n",
       "167  17941  2016    18989        0           0            0         1   \n",
       "225  12493  2014    51330        0           0            0         0   \n",
       "270   7994  2007   116065        0           1            0         1   \n",
       "\n",
       "     M_CamryLE  M_CamrySE  M_CamryXLE  \n",
       "7            0          0           0  \n",
       "11           1          0           0  \n",
       "167          0          1           0  \n",
       "225          0          0           0  \n",
       "270          0          0           0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Factorizar todas las columnas que comienzan con 'M_Camry'\n",
    "columns_to_factorize = [col for col in data.columns if col.startswith('M_Camry')]\n",
    "for col in columns_to_factorize:\n",
    "    data[col] = pd.factorize(data[col])[0]\n",
    "# Visualización del dataset después de la transformación\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>M_Camry</th>\n",
       "      <th>M_Camry4dr</th>\n",
       "      <th>M_CamryBase</th>\n",
       "      <th>M_CamryL</th>\n",
       "      <th>M_CamryLE</th>\n",
       "      <th>M_CamrySE</th>\n",
       "      <th>M_CamryXLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10495.000000</td>\n",
       "      <td>10495.000000</td>\n",
       "      <td>10495.000000</td>\n",
       "      <td>10495.000000</td>\n",
       "      <td>10495.000000</td>\n",
       "      <td>10495.000000</td>\n",
       "      <td>10495.000000</td>\n",
       "      <td>10495.000000</td>\n",
       "      <td>10495.000000</td>\n",
       "      <td>10495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14538.403716</td>\n",
       "      <td>2013.553883</td>\n",
       "      <td>52509.430395</td>\n",
       "      <td>0.056313</td>\n",
       "      <td>0.158456</td>\n",
       "      <td>0.012292</td>\n",
       "      <td>0.951787</td>\n",
       "      <td>0.236494</td>\n",
       "      <td>0.376370</td>\n",
       "      <td>0.111863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3922.420961</td>\n",
       "      <td>3.116585</td>\n",
       "      <td>36791.736601</td>\n",
       "      <td>0.230535</td>\n",
       "      <td>0.365186</td>\n",
       "      <td>0.110189</td>\n",
       "      <td>0.214227</td>\n",
       "      <td>0.424949</td>\n",
       "      <td>0.484498</td>\n",
       "      <td>0.315213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5002.000000</td>\n",
       "      <td>1998.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11999.000000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>26461.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15000.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>41680.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16999.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>71355.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>32444.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>232658.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Price          Year        Mileage       M_Camry    M_Camry4dr  \\\n",
       "count  10495.000000  10495.000000   10495.000000  10495.000000  10495.000000   \n",
       "mean   14538.403716   2013.553883   52509.430395      0.056313      0.158456   \n",
       "std     3922.420961      3.116585   36791.736601      0.230535      0.365186   \n",
       "min     5002.000000   1998.000000       5.000000      0.000000      0.000000   \n",
       "25%    11999.000000   2012.000000   26461.000000      0.000000      0.000000   \n",
       "50%    15000.000000   2014.000000   41680.000000      0.000000      0.000000   \n",
       "75%    16999.000000   2016.000000   71355.500000      0.000000      0.000000   \n",
       "max    32444.000000   2018.000000  232658.000000      1.000000      1.000000   \n",
       "\n",
       "        M_CamryBase      M_CamryL     M_CamryLE     M_CamrySE    M_CamryXLE  \n",
       "count  10495.000000  10495.000000  10495.000000  10495.000000  10495.000000  \n",
       "mean       0.012292      0.951787      0.236494      0.376370      0.111863  \n",
       "std        0.110189      0.214227      0.424949      0.484498      0.315213  \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.000000      1.000000      0.000000      0.000000      0.000000  \n",
       "50%        0.000000      1.000000      0.000000      0.000000      0.000000  \n",
       "75%        0.000000      1.000000      0.000000      1.000000      0.000000  \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analisis descriptivo\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10495 entries, 7 to 399976\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   Price        10495 non-null  int64\n",
      " 1   Year         10495 non-null  int64\n",
      " 2   Mileage      10495 non-null  int64\n",
      " 3   M_Camry      10495 non-null  int64\n",
      " 4   M_Camry4dr   10495 non-null  int64\n",
      " 5   M_CamryBase  10495 non-null  int64\n",
      " 6   M_CamryL     10495 non-null  int64\n",
      " 7   M_CamryLE    10495 non-null  int64\n",
      " 8   M_CamrySE    10495 non-null  int64\n",
      " 9   M_CamryXLE   10495 non-null  int64\n",
      "dtypes: int64(10)\n",
      "memory usage: 901.9 KB\n"
     ]
    }
   ],
   "source": [
    "# Información del dataset\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de variables predictoras (X) y variable de interés (y)\n",
    "y = data['Price']\n",
    "X = data.drop(['Price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de datos en set de entrenamiento y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 1 - Árbol de decisión manual\n",
    "\n",
    "En la celda 1 creen un árbol de decisión **manualmente**  que considere los set de entrenamiento y test definidos anteriormente y presenten el RMSE y MAE del modelo en el set de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de parámetros y criterios de parada\n",
    "max_depth = None\n",
    "num_pct = 10\n",
    "max_features = None\n",
    "min_gain=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var(y):\n",
    "    \"\"\"Calcula la varianza de los valores en y.\"\"\"\n",
    "    return y.var() if len(y) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_impurity(X_col, y, split):\n",
    "    \"\"\"Calcula la reducción de impureza al hacer un split en X_col.\"\"\"\n",
    "    filter_l = X_col < split\n",
    "    y_l, y_r = y[filter_l], y[~filter_l]\n",
    "    \n",
    "    n_l, n_r = len(y_l), len(y_r)\n",
    "    if n_l == 0 or n_r == 0:\n",
    "        return 0  # Evita splits innecesarios\n",
    "    \n",
    "    impurity_reduction = var(y) - (n_l / (n_l + n_r) * var(y_l) + n_r / (n_l + n_r) * var(y_r))\n",
    "    return impurity_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(X, y, num_pct=10):\n",
    "    \"\"\"Encuentra la mejor división basada en la máxima reducción de impureza.\"\"\"\n",
    "    best = {'feature': None, 'split': None, 'gain': -np.inf}\n",
    "    \n",
    "    for j in range(X.shape[1]):\n",
    "        unique_values = np.percentile(X.iloc[:, j], np.linspace(0, 100, num_pct + 2)[1:-1])\n",
    "        unique_values = np.unique(unique_values)\n",
    "        \n",
    "        for split in unique_values:\n",
    "            gain = var_impurity(X.iloc[:, j], y, split)\n",
    "            if gain > best['gain']:\n",
    "                best = {'feature': j, 'split': split, 'gain': gain}\n",
    "    \n",
    "    return best['feature'], best['split'], best['gain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_grow(X, y, level=0, min_gain=0.001, max_depth=None, num_pct=10):\n",
    "    \"\"\"Construye el árbol de decisión de manera recursiva.\"\"\"\n",
    "    if len(y) == 1:\n",
    "        return {'y_pred': y.iloc[0], 'y_prob': 0.5, 'level': level, 'split': None, 'n_samples': 1, 'gain': 0}\n",
    "    \n",
    "    j, split, gain = best_split(X, y, num_pct)\n",
    "    \n",
    "    # Condiciones de parada\n",
    "    if gain < min_gain or (max_depth is not None and level >= max_depth):\n",
    "        return {'y_pred': y.mean(), 'y_prob': (y.sum() + 1) / (len(y) + 2), 'level': level, 'split': None, 'n_samples': len(y), 'gain': gain}\n",
    "    \n",
    "    filter_l = X.iloc[:, j] < split\n",
    "    X_l, y_l, X_r, y_r = X[filter_l], y[filter_l], X[~filter_l], y[~filter_l]\n",
    "    \n",
    "    return {\n",
    "        'y_pred': y.mean(),\n",
    "        'y_prob': (y.sum() + 1) / (len(y) + 2),\n",
    "        'level': level,\n",
    "        'split': (j, split),\n",
    "        'n_samples': len(y),\n",
    "        'gain': gain,\n",
    "        'sl': tree_grow(X_l, y_l, level + 1, min_gain, max_depth, num_pct),\n",
    "        'sr': tree_grow(X_r, y_r, level + 1, min_gain, max_depth, num_pct)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_predict(X, tree, proba=False):\n",
    "    \"\"\"Predice valores para X usando el árbol de decisión.\"\"\"\n",
    "    predictions = np.empty(X.shape[0])\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        node = tree\n",
    "        while node['split'] is not None:\n",
    "            feature, split = node['split']\n",
    "            node = node['sl'] if X.iloc[i, feature] < split else node['sr']\n",
    "        predictions[i] = node['y_prob'] if proba else node['y_pred']\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo\n",
    "tree = tree_grow(X_train, y_train, level=0, min_gain=0.001, max_depth=3, num_pct=10)\n",
    "# Predicción y evaluación\n",
    "yPredict_Tree = tree_predict(X_test, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1921.00\n",
      "MAE: 1445.81\n",
      "R² Score: 0.7587\n"
     ]
    }
   ],
   "source": [
    "MSETREE = np.average(np.square(yPredict_Tree-y_test))\n",
    "RMSETREE = np.sqrt(MSETREE)\n",
    "MAETREE = mean_absolute_error(y_test, yPredict_Tree)\n",
    "R2Tree = r2_score(y_test, yPredict_Tree)\n",
    "\n",
    "# Mostramos los resultados\n",
    "print(f'RMSE: {RMSETREE:.2f}')\n",
    "print(f'MAE: {MAETREE:.2f}')\n",
    "print(f\"R² Score: {R2Tree:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios Árbol de Decisión Manual** <br>\n",
    "<p style=\"text-align: justify;\">\n",
    "En este punto se construyó un árbol de decisión de forma manual, utilizando como criterio principal la reducción de la varianza para evaluar la pureza de los nodos. El proceso de partición fue implementado a través de la función <code>best_split</code>, la cual explora múltiples puntos de corte en cada variable, seleccionando aquel que maximiza la reducción de impureza (es decir, la varianza ponderada antes y después del split). Esta estrategia permite elegir divisiones que separan los datos de forma más homogénea dentro de cada rama.\n",
    "</p>\n",
    "<p style=\"text-align: justify;\">\n",
    "De forma complementaria, se probó una versión alternativa del árbol utilizando el Error Cuadrático Medio (MSE) como métrica para determinar la calidad de las particiones. Sin embargo, los resultados obtenidos con ambos enfoques fueron muy similares. Por esta razón, y considerando que la varianza es una forma directa e intuitiva de evaluar la dispersión en problemas de regresión, se optó por mantener la reducción de la varianza como el criterio final.\n",
    "</p>\n",
    "<p style=\"text-align: justify;\">\n",
    "En cuanto al desempeño, el modelo obtuvo un RMSE de 1,921.00. El MAE de 1,445.81 muestra que la mayoría de las predicciones se mantuvieron razonablemente cercanas al valor real, aunque hubo algunos casos con errores mayores, dada la diferencia del mismo con el RMSE. Finalmente, el R² de 0.7587 sugiere que el modelo es capaz de explicar un 75.87% de la variabilidad de los datos de prueba.\n",
    "</p>\n",
    "<p style=\"text-align: justify;\">\n",
    "Estos resultados son aceptables para tratarse de una implementación manual sin optimización de hiperparámetros, y reflejan que el árbol logra captar correctamente las tendencias generales en los datos. No obstante, hay espacio para mejorar el desempeño del modelo mediante técnicas de ensamble como Bagging o Random Forest, así como mediante el ajuste de sus parámetros.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 2 - Bagging manual\n",
    "\n",
    "En la celda 2 creen un modelo bagging **manualmente** con 10 árboles de regresión y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELADO BAGGING MANUAL CON 10 ÁRBOLES\n",
      "EVALUACIÓN DEL MODELO DE BAGGING MANUAL\n",
      "Conjunto de Prueba:\n",
      "RMSE: 1821.10\n",
      "MAE: 1354.52\n",
      "R2: 0.7832\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)  # Fijamos la semilla para reproducibilidad\n",
    "n_trees = 10\n",
    "max_depth = None\n",
    "max_features = None  # Usa todas las características\n",
    "\n",
    "predictions_train = []\n",
    "predictions_test = []\n",
    "trees = []\n",
    "\n",
    "print(\"MODELADO BAGGING MANUAL CON \" + str(n_trees) + \" ÁRBOLES\")\n",
    "\n",
    "for i in range(n_trees):\n",
    "    # Muestra bootstrap\n",
    "    bootstrap_idx = np.random.choice(range(len(X_train)), size=len(X_train), replace=True)\n",
    "    X_bootstrap = X_train.iloc[bootstrap_idx]\n",
    "    y_bootstrap = y_train.iloc[bootstrap_idx]\n",
    "    \n",
    "    # Modelo\n",
    "    tree = DecisionTreeRegressor(\n",
    "        max_depth=max_depth,\n",
    "        max_features=max_features,\n",
    "        random_state=i\n",
    "    )\n",
    "    tree.fit(X_bootstrap, y_bootstrap)\n",
    "    trees.append(tree)\n",
    "\n",
    "    # Predicciones\n",
    "    predictions_train.append(tree.predict(X_train))\n",
    "    predictions_test.append(tree.predict(X_test))\n",
    "\n",
    "# Promedio de predicciones\n",
    "y_train_bgm = np.mean(predictions_train, axis=0)\n",
    "y_test_bgm = np.mean(predictions_test, axis=0)\n",
    "\n",
    "# Evaluación del modelo TEST\n",
    "MSE_BaggingManual = mean_squared_error(y_test, y_test_bgm)\n",
    "RMSE_BaggingManual = np.sqrt(MSE_BaggingManual)\n",
    "MAE_BaggingManual = mean_absolute_error(y_test, y_test_bgm)\n",
    "R2_BaggingManual = r2_score(y_test, y_test_bgm)\n",
    "\n",
    "# Impresión de resultados\n",
    "print(\"EVALUACIÓN DEL MODELO DE BAGGING MANUAL\")\n",
    "print(\"Conjunto de Prueba:\")\n",
    "print(f\"RMSE: {RMSE_BaggingManual:.2f}\")\n",
    "print(f\"MAE: {MAE_BaggingManual:.2f}\")\n",
    "print(f\"R2: {R2_BaggingManual:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo de Bagging Manual** <br>\n",
    "<p style=\"text-align: justify;\">\n",
    "Se implementó manualmente un modelo de Bagging utilizando 10 árboles de regresión, cada uno entrenado sobre una muestra bootstrap con reemplazo extraída del conjunto de entrenamiento. En cada iteración, se construyó un árbol sin restricciones en la profundidad (`max_depth`) ni en el número de características utilizadas (`max_features`). Las predicciones individuales de cada árbol fueron promediadas para obtener una predicción.<p>\n",
    "<p style=\"text-align: justify;\">\n",
    "Al evaluar el modelo sobre el conjunto de prueba, se obtuvo un RMSE de 1,821.10, un MAE de 1,354.52 y un R² de 0.7832. Estos resultados indican que el modelo logra capturar aproximadamente el 78.3% de la variabilidad en los datos, con un error absoluto promedio de 1,354 unidades. El RMSE, al ser mayor que el MAE, sugiere la presencia de algunos errores puntuales más altos, probablemente asociados a valores extremos.<p>\n",
    "\n",
    "**Recomendaciones** <br>\n",
    "Para mejorar el desempeño del modelo se podría pensar en:\n",
    "1. Aumentar el número de árboles (`n_trees`): Aunque 10 árboles ya permiten notar mejoras respecto a un modelo base, incrementar este número puede estabilizar aún más las predicciones y reducir la varianza.\n",
    "2. Validación cruzada: Implementar validación cruzada durante la evaluación permitiría obtener una estimación más robusta del rendimiento del modelo, especialmente útil cuando los datos presentan alta variabilidad.\n",
    "3. Explorar el uso de `max_samples` y `max_features`: Estas opciones pueden incorporarse también en la versión manual para controlar el grado de aleatoriedad del modelo, afectando la diversidad de los árboles y, por tanto, el sesgo y la varianza del ensamble.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 3 - Bagging con librería\n",
    "\n",
    "En la celda 3, con la librería sklearn, entrenen un modelo bagging con 10 árboles de regresión y el parámetro `max_features` igual a `log(n_features)` y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUACIÓN DEL MODELO DE BAGGING LIBRERÍA CON RESTRICCIONES \n",
      "\n",
      "Número total de características: 9\n",
      "Número de características seleccionadas para entrenar cada árbol: 3\n",
      "RMSE: 2274.14\n",
      "MAE: 1744.45\n",
      "R²: 0.6619\n"
     ]
    }
   ],
   "source": [
    "# Número de características\n",
    "n_features = X_train.shape[1]\n",
    "max_features = int(np.log2(n_features))\n",
    "\n",
    "# Entrenamiento del modelo con sklearn\n",
    "bagging_model_log = BaggingRegressor(\n",
    "    estimator=DecisionTreeRegressor(),\n",
    "    n_estimators=10,\n",
    "    max_features=max_features,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "bagging_model_log.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "y_test_bgl = bagging_model_log.predict(X_test)\n",
    "\n",
    "# Evaluación del modelo de Bagging con librería en el conjunto de prueba\n",
    "RMSE_BaggingLibreria = np.sqrt(mean_squared_error(y_test, y_test_bgl))\n",
    "MAE_BaggingLibreria = mean_absolute_error(y_test, y_test_bgl)\n",
    "R2_BaggingLibreria = r2_score(y_test, y_test_bgl)\n",
    "\n",
    "print(\"\\nEVALUACIÓN DEL MODELO DE BAGGING LIBRERÍA CON RESTRICCIONES \\n\")\n",
    "print(f\"Número total de características: {n_features}\")\n",
    "print(f\"Número de características seleccionadas para entrenar cada árbol: {max_features}\")\n",
    "print(f\"RMSE: {RMSE_BaggingLibreria:.2f}\")\n",
    "print(f\"MAE: {MAE_BaggingLibreria:.2f}\")\n",
    "print(f\"R²: {R2_BaggingLibreria:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusión sobre el modelo de Bagging de 10 árboles con max_features = log2(n_features)** <br>\n",
    "<p style=\"text-align: justify;\">\n",
    "Este modelo de Bagging utilizó 10 árboles de regresión, donde cada árbol fue entrenado sobre un subconjunto aleatorio de 3 variables (de un total de 9 disponibles), determinado por la restricción `max_features = log2(n_features)`.<p>\n",
    "<p style=\"text-align: justify;\">\n",
    "Sin embargo, en este caso específico, la restricción aplicada parece haber sido demasiado estricta, limitando la información disponible para cada estimador. Como resultado, el poder predictivo de los árboles individuales se ve comprometido, lo que se refleja en un desempeño inferior en comparación con modelos que no aplicaron esta restricción. El R² de 0.6619, junto con un RMSE de 2274.14 y un MAE de 1744.45, indican que el modelo no logra capturar adecuadamente la variabilidad en los precios, y comete errores de magnitud considerable en sus predicciones.<p>\n",
    "<p style=\"text-align: justify;\">\n",
    "Por tanto, si bien la aleatoriedad introducida por `max_features` puede ser beneficiosa en ciertos escenarios, en este caso particular ha perjudicado el rendimiento del modelo. Sería recomendable evaluar otros valores de `max_features` menos restrictivos o utilizar métodos de búsqueda de hiperparámetros para encontrar un mejor equilibrio entre diversidad y capacidad predictiva.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 4 - Random forest con librería\n",
    "\n",
    "En la celda 4, usando la librería sklearn entrenen un modelo de Randon Forest para regresión  y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicion y entrenamiento del modelo Random Forest\n",
    "rf_regressor = RandomForestRegressor()\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "# Predicciones\n",
    "y_pred_base = rf_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo Random Forest\n",
    "RMSE_RandomForest = np.sqrt(mean_squared_error(y_test, y_pred_base))\n",
    "MAE_Random_Forest = mean_absolute_error(y_test, y_pred_base)\n",
    "R2_RandomForest = r2_score(y_test, y_pred_base)\n",
    "\n",
    "# Resultados del modelo Random Forest\n",
    "print(\"Random Forest\")\n",
    "print(f\"RMSE: {RMSE_RandomForest:.4f}\")\n",
    "print(f\"MAE: {MAE_Random_Forest:.4f}\")\n",
    "print(f\"R2: {R2_RandomForest:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios sobre el desempeño** <br>\n",
    "\n",
    "El modelo de Random Forest con su configuración predeterminada mostró un rendimiento aceptable. El coeficiente de determinación (**R² = 0.7991**) indica que el modelo logra explicar alrededor del 79.5% de la variabilidad en los datos de prueba, lo cual no está mal, pero aún se podría optimizar, teniendo en cuenta que no se calibraró ningún parámetro.\n",
    "\n",
    "En cuanto al error, los valores de **MAE (1305.79)** y **RMSE (1753.15)** sugieren que, en promedio, las predicciones se desvían del valor real en aproximadamente 1314 $. Además, el RMSE más alto indica que hay ciertos casos con errores más grandes, probablemente por la presencia de valores extremos o atípicos (ouliers) que el modelo no maneja tan bien. El desempeño del modelo podría mejorarse ajustando los hiperparámetros clave, como `max_depth`, `n_estimators` y `max_features`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 5 - Calibración de parámetros Random forest\n",
    "\n",
    "En la celda 5, calibren los parámetros max_depth, max_features y n_estimators del modelo de Randon Forest para regresión, comenten sobre el desempeño del modelo y describan cómo cada parámetro afecta el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición del Grid de Hiperparámetros y Configuración del GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "rf_regressor = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf_regressor, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento con GridSearchCV y Selección de Mejores Parámetros\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Mejores parámetros encontrados:\")\n",
    "print(best_params)\n",
    "print(\"Mejor puntuación:\")\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento del modelo Random Forest con los mejores parámetros\n",
    "rf_regressor = RandomForestRegressor(**best_params, random_state=42)\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "# Predicciones\n",
    "y_pred_grid = rf_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del Modelo con Métricas de Desempeño\n",
    "RMSE_RandomForest_Grid = np.sqrt(mean_squared_error(y_test, y_pred_grid))\n",
    "MAE_RandomForest_Grid = mean_absolute_error(y_test, y_pred_grid)\n",
    "R2_RandomForest_Grid = r2_score(y_test, y_pred_grid)\n",
    "\n",
    "# Resultados del modelo Random Forest con GridSearchCV\n",
    "print(\"Random Forest con GridSearchCV\")\n",
    "print(f\"RMSE: {RMSE_RandomForest_Grid:.4f}\")\n",
    "print(f\"MAE: {MAE_RandomForest_Grid:.4f}\")\n",
    "print(f\"R2: {R2_RandomForest_Grid:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Procedimiento** <br>\n",
    "<p style=\"text-align: justify;\"> Se implementó GridSearchCV con validación cruzada para calibrar los hiperparámetros del modelo Random Forest. Se exploraron combinaciones de <code>n_estimators</code>, <code>max_depth</code> y <code>max_features</code>, seleccionando la combinación que minimizó el error cuadrático medio (RMSE). Posteriormente, el modelo fue entrenado con los mejores parámetros y evaluado sobre el conjunto de prueba para validar su rendimiento.</p>\n",
    "\n",
    "**Relevancia de Parámetros Calibrados**\n",
    "<p style=\"text-align: justify;\"> El proceso de optimización con GridSearchCV determinó que la mejor combinación de hiperparámetros fue:<br> <strong><code>n_estimators = 150</code>, <code>max_depth = 10</code>, <code>max_features = 'sqrt'</code></strong>.<br><br> <code>n_estimators</code>: Indica el número de árboles en el bosque. Un mayor número generalmente mejora la precisión, pero incrementa el tiempo de cómputo. En este caso, 150 árboles generaron un buen equilibrio.<br> <code>max_depth</code>: Controla la profundidad máxima de los árboles. En este caso el proceso de calibración arrojó un valor de 10.<br> <code>max_features</code>: Indica el número o fracción de variables tenidas en cuenta para cada división. El proceso de calibración arrojó 'sqrt' como definición de variables a consideraar. El uso de 'sqrt' introduce aleatoriedad, lo cual beneficia la diversidad entre árboles y reduce el riesgo de sobreajuste.</p>\n",
    "\n",
    "**Evaluación del Desempeño del Modelo**\n",
    "<p style=\"text-align: justify;\"> El modelo ajustado con GridSearchCV obtuvo un RMSE de <strong>1566.4746</strong> y un MAE de <strong>1147.8526</strong>, lo que representa una mejora en comparación con el modelo inicial (Random Forest con parámetros predeterminados). La reducción en estos valores sugiere un mejor ajuste general del modelo. Además, el coeficiente de determinación R² fue de <strong>0.8396</strong>, indicando que el modelo explica una proporción considerable de la variabilidad en los datos. En conjunto, estos resultados muestran que el modelo calibrado tiene un buen desempeño y capacidad de generalización.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 6 - XGBoost con librería\n",
    "\n",
    "En la celda 6 implementen un modelo XGBoost de regresión con la librería sklearn y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Definicion y entrenamiento del modelo XGBRegressor\n",
    "XGBReg = XGBRegressor()\n",
    "# Entrenamiento (fit) y desempeño del modelo XGBRegressor\n",
    "XGBReg.fit(X_train, y_train)\n",
    "y_pred = XGBReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo\n",
    "MAE_XGBReg = mean_absolute_error(y_test, y_pred)\n",
    "RMSE_XGBReg = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "R2_XGBReg = r2_score(y_test, y_pred)\n",
    "\n",
    "# Resultados\n",
    "print('MAE: ', f'{MAE_XGBReg:.4f}')\n",
    "print('RMSE: ', f'{RMSE_XGBReg:.4f}')\n",
    "print('R2: ', f'{R2_XGBReg:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios Sobre el Desempeño del Modelo** <br>\n",
    "<p style=\"text-align: justify;\">\n",
    "El modelo XGBoost presenta un buen desempeño general. El coeficiente R2 = 0.8315 indica que el modelo explica más del 83% de la varianza en los datos de test, lo cual es un buen resultado en problemas de regresión. El MAE (1185) sugiere que el modelo se desvía en promedio 1185 unidades del valor real, mientras que el RMSE (1605) indica que hay algunos errores más grandes.<p>\n",
    "<p style=\"text-align: justify;\">\n",
    "A continuación, se presenta un gráfico de dispersión entre los valores predichos y valores reales del modelo así como una interpretación de la misma:<p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica de dispersión entre valores reales y predicciones\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.xlabel(\"Valores reales\")\n",
    "plt.ylabel(\"Predicciones\")\n",
    "plt.title(\"Predicciones vs Valores reales - XGBoost Librería\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">\n",
    "El gráfico de dispersión de predicciones vs valores reales muestra una correlación positiva. La línea roja representa las predicciones ideales, es decir el caso donde y_test = y_pred en todos los puntos. Como se observa en la gráfica, la mayoría de los puntos están cercanos a esta línea, lo que indica que el modelo realiza predicciones correctas. Se observa cierta dispersión creciente a medida que aumentan los valores de y_test, lo que podría indicar que el modelo tiene más dificultad en predecir los valores extremos (posiblemente debido a outliers o a una varianza mayor en esos rangos). En general, la forma alineada de los puntos con la línea roja indica un buen ajuste del modelo, lo cual es soportado por las métricas de desempeño. <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recomendaciones**\n",
    "<p style=\"text-align: justify;\">\n",
    "Como recomendación, se sugiere aplicar un método de calibración de hiperparámetros con validación cruzada, como por ejemplo GridSearchCV o RandomizedSearchCV. Esto permitiría encontrar combinaciones óptimas de parámetros relevantes —como learning_rate— mejorando el desempeño del modelo. Además, el uso de validación cruzada contribuye a reducir el riesgo de sobreajuste (overfitting), al garantizar que el modelo generalice adecuadamente sobre distintos subconjuntos de datos.<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 7 - Calibración de parámetros XGBoost\n",
    "\n",
    "En la celda 7 calibren los parámetros learning rate, gamma y colsample_bytree del modelo XGBoost para regresión, comenten sobre el desempeño del modelo y describan cómo cada parámetro afecta el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibracion con GridSearchCV\n",
    "# Definir la grilla de hiperparámetros\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    \"gamma\": [0, 0.1, 0.3, 0.5, 1, 5],\n",
    "    \"colsample_bytree\": [0.4, 0.6, 0.8, 1.0]\n",
    "}\n",
    "# Definir el modelo con eval_metric incluido\n",
    "xgb = XGBRegressor(eval_metric=\"rmse\")\n",
    "# Definir el GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    xgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    verbose=0\n",
    ")\n",
    "# Ajustar el modelo sin early_stopping_rounds\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejor modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "# Mejor hiperparámetros\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Mejores hiperparámetros: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir con el mejor modelo\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "# Evaluación del modelo\n",
    "MAE_XGBGridSearchCV = mean_absolute_error(y_test, y_pred_best)\n",
    "RMSE_XGBGridSearchCV = np.sqrt(mean_squared_error(y_test, y_pred_best))\n",
    "R2_XGBGridSearchCV = r2_score(y_test, y_pred_best)\n",
    "# Resultados\n",
    "print('MAE: ', f'{MAE_XGBGridSearchCV:.4f}')\n",
    "print('RMSE: ', f'{RMSE_XGBGridSearchCV:.4f}')\n",
    "print('R2: ', f'{R2_XGBGridSearchCV:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Procedimiento** <br>\n",
    "<p style=\"text-align: justify;\">\n",
    "Se implementó GridSearchCV con validación cruzada para calibrar los hiperparámetros del modelo XGBRegressor. Se buscaron combinaciones óptimas de learning_rate, gamma y colsample_bytree, seleccionando el modelo con menor error cuadrático medio (RMSE) y evaluando su rendimiento sobre el set de prueba. <p>\n",
    "\n",
    "**Relevancia de Parámetros Calibrados**\n",
    "><p style=\"text-align: justify;\">\n",
    ">learning_rate: Establece la tasa de aprendizaje del modelo. Un valor bajo mejora la generalización pero requiere más árboles. Si es muy alto, puede causar sobreajuste o saltarse óptimos.<br><br>\n",
    ">gamma: Define el umbral mínimo de mejora en la pérdida para que el árbol realice una partición. Valores altos lo hacen más conservador, ayudando a reducir sobreajuste pero también pudiendo limitar la capacidad predictiva.<br><br>\n",
    ">colsample_bytree: Proporción de columnas utilizadas al construir cada árbol. Valores bajos introducen aleatoriedad, lo cual ayuda a evitar el sobreajuste; valores más altos permiten al modelo usar más información, lo cual puede ser útil si no hay mucha colinealidad.<p>\n",
    "\n",
    "**Evaluación del Desempeño del Modelo**\n",
    "<p style=\"text-align: justify;\">\n",
    "El modelo ajustado con GridSearchCV logró un MAE de 1136.5352 y un RMSE de 1545.6715, mejorando respecto al modelo del punto anterior. Estos valores indican que, en promedio, el error de predicción se redujo, y la menor diferencia entre MAE y RMSE sugiere que el modelo está manejando mejor los valores extremos. En conjunto con el R cuadrado (0.8438), el desempeño del modelo es bueno y está mejor calibrado que el modelo estimado inicialmente.<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 8 - Comparación y análisis de resultados\n",
    "En la celda 8 comparen los resultados obtenidos de los diferentes modelos (random forest y XGBoost) y comenten las ventajas del mejor modelo y las desventajas del modelo con el menor desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = ['Arbol_Manual', 'Bagging_Manual', 'Bagging_Libreria', 'Random_Forest', 'Random_Forest_Grid', 'XGBRegressor', 'XGBRegressor_Grid']\n",
    "RMSE = [RMSETREE, RMSE_BaggingManual, RMSE_BaggingLibreria, RMSE_RandomForest, RMSE_RandomForest_Grid, RMSE_XGBReg, RMSE_XGBGridSearchCV]\n",
    "MAE = [MAETREE, MAE_BaggingManual, MAE_BaggingLibreria, MAE_Random_Forest, MAE_RandomForest_Grid, MAE_XGBReg, MAE_XGBGridSearchCV]\n",
    "R2 = [R2Tree, R2_BaggingManual, R2_BaggingLibreria, R2_RandomForest, R2_RandomForest_Grid, R2_XGBReg, R2_XGBGridSearchCV]\n",
    "\n",
    "# Crear subplots\n",
    "fig, axs = plt.subplots(3, 1, figsize=(20, 16))\n",
    "\n",
    "# Gráfico 1: Comparar modelos por RMSE\n",
    "sns.barplot(x=modelos, y=RMSE, ax=axs[0])\n",
    "axs[0].set_title('Comparación de Modelos por RMSE')\n",
    "axs[0].set_xlabel('Modelos')\n",
    "axs[0].set_ylabel('RMSE')\n",
    "for i in range(len(modelos)):\n",
    "    axs[0].text(i, RMSE[i], round(RMSE[i], 4), ha='center', va='bottom')\n",
    "\n",
    "# Gráfico 2: Comparar modelos por F1\n",
    "sns.barplot(x=modelos, y=MAE, ax=axs[1])\n",
    "axs[1].set_title('Comparación de Modelos por MAE')\n",
    "axs[1].set_xlabel('Modelos')\n",
    "axs[1].set_ylabel('MAE')\n",
    "for i in range(len(modelos)):\n",
    "    axs[1].text(i, MAE[i], round(MAE[i], 4), ha='center', va='bottom')\n",
    "\n",
    "# Gráfico 3: Comparar modelos por R2\n",
    "sns.barplot(x=modelos, y=R2, ax=axs[2])\n",
    "axs[2].set_title('Comparación de Modelos por R2')\n",
    "axs[2].set_xlabel('Modelos')\n",
    "axs[2].set_ylabel('R2')\n",
    "for i in range(len(modelos)):\n",
    "    axs[2].text(i, R2[i], round(R2[i], 4), ha='center', va='bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">\n",
    "La gráfica anterior compara los resultados de los modelos comprando el RMSE, MAE y R². El modelo XGBRegressor_Grid se posiciona como el más eficaz, obteniendo el menor error (RMSE y MAE) y el mayor poder explicativo (R² de 0.8438). Le siguen el Random Forest con calibración de parámetros por GridSearchCV(Random_Forest_Grid) y XGBRegressor sin calibración de parámetros. En contraste, Bagging estimado con librería y con restricción de parámetros  muestra el peor desempeño, con errores significativamente más altos y un R² de apenas 0.4956. Las versiones manuales de los modelos tienen resultados aceptables, pero son superadas por las variantes optimizadas. Esto destaca la importancia de la selección cuidadosa y ajuste de hiperparámetros. <p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
